{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12993941,"sourceType":"datasetVersion","datasetId":8224837}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:46:08.874058Z","iopub.execute_input":"2025-09-28T19:46:08.874302Z","iopub.status.idle":"2025-09-28T19:46:09.195083Z","shell.execute_reply.started":"2025-09-28T19:46:08.874274Z","shell.execute_reply":"2025-09-28T19:46:09.194480Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/egiptura-database/Egiptura Database.pdf\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# حل التعارض: datasets==3.6.0 بتحتاج fsspec[http]==2023.6.0\n!pip -q install -U \"fsspec[http]==2023.6.0\" \"datasets==3.6.0\"\n\n# ثبّت الباقي بدون كسر الاعتمادات\n!pip -q install -U \"transformers>=4.43,<5\" \"accelerate>=0.33,<1\" \\\n                   \"sentence-transformers>=2.5,<3\" \"faiss-cpu>=1.7,<2\" \\\n                   \"pypdf>=3,<5\" \"safetensors>=0.4.2\" \"huggingface_hub>=0.23,<1\"\n\n# تأكيد الإصدارات (اختياري)\nimport importlib, pkgutil\nfor m in [\"fsspec\",\"datasets\",\"transformers\",\"accelerate\",\"sentence_transformers\",\"faiss\",\"pypdf\"]:\n    try:\n        mod = importlib.import_module(m if m!=\"faiss\" else \"faiss\")\n        print(m, getattr(mod, \"__version__\", \"\"))\n    except Exception as e:\n        print(m, \"ERR:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:46:09.196905Z","iopub.execute_input":"2025-09-28T19:46:09.197250Z","iopub.status.idle":"2025-09-28T19:46:22.140235Z","shell.execute_reply.started":"2025-09-28T19:46:09.197229Z","shell.execute_reply":"2025-09-28T19:46:22.139516Z"}},"outputs":[{"name":"stdout","text":"fsspec 2023.6.0\ndatasets 3.6.0\ntransformers 4.56.2\naccelerate 0.34.2\nsentence_transformers 2.7.0\nfaiss 1.12.0\npypdf 4.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# If needed (Kaggle/Colab): uncomment & run\n%pip install -q  torch accelerate bitsandbytes fastapi uvicorn nest_asyncio pyngrok requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:46:22.141112Z","iopub.execute_input":"2025-09-28T19:46:22.141585Z","iopub.status.idle":"2025-09-28T19:46:25.340342Z","shell.execute_reply.started":"2025-09-28T19:46:22.141545Z","shell.execute_reply":"2025-09-28T19:46:25.339183Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:46:25.341422Z","iopub.execute_input":"2025-09-28T19:46:25.341677Z","iopub.status.idle":"2025-09-28T19:46:28.585189Z","shell.execute_reply.started":"2025-09-28T19:46:25.341654Z","shell.execute_reply":"2025-09-28T19:46:28.584243Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.47.0)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2023.6.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# لو الريبو Private\nfrom huggingface_hub import login\nlogin()  # هيفتح لك إدخال التوكن\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:46:28.586434Z","iopub.execute_input":"2025-09-28T19:46:28.587012Z","iopub.status.idle":"2025-09-28T19:46:28.608464Z","shell.execute_reply.started":"2025-09-28T19:46:28.586982Z","shell.execute_reply":"2025-09-28T19:46:28.607651Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1009852a004c44aaa8dcbb70047bb7ad"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch, os, re\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nREPO_ID = \"HatemAhmed44/egiptura-adapter\"   # عدّلها لو اختلفت\n\ntok = AutoTokenizer.from_pretrained(REPO_ID, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    REPO_ID,\n    trust_remote_code=True,\n    torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),\n    device_map=(\"auto\" if torch.cuda.is_available() else None),\n)\nmodel.eval()\n\n# ضمان وجود pad_token\nif tok.pad_token is None:\n    tok.pad_token = tok.eos_token\n\nprint(\"Loaded:\", REPO_ID, \"| device:\", model.device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:46:28.609501Z","iopub.execute_input":"2025-09-28T19:46:28.609764Z","iopub.status.idle":"2025-09-28T19:47:25.946907Z","shell.execute_reply.started":"2025-09-28T19:46:28.609747Z","shell.execute_reply":"2025-09-28T19:47:25.946293Z"}},"outputs":[{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n2025-09-28 19:46:30.425122: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759088790.448661     140 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759088790.453754     140 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edd4e22712f43daabb9cd6de1d5ef68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2510c5d72d164c1cacb010ab18c56eea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f383adcb6e453aaa0a76646986ab08"}},"metadata":{}},{"name":"stdout","text":"Loaded: HatemAhmed44/egiptura-adapter | device: cuda:0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nif \"vectordb\" not in globals():\n    from pypdf import PdfReader\n    from sentence_transformers import SentenceTransformer\n    import faiss\n    import numpy as np\n\n    PDF_PATH = \"/kaggle/input/egiptura-database/Egiptura Database.pdf\"  # عدّل المسار لو لزم\n\n    def load_pdf_text(path):\n        reader = PdfReader(path)\n        pages = [p.extract_text() or \"\" for p in reader.pages]\n        text = \"\\n\".join(pages)\n        return text\n\n    def chunk_text(text, chunk_size=900, overlap=150):\n        chunks = []\n        i = 0\n        while i < len(text):\n            chunk = text[i:i+chunk_size]\n            chunks.append(chunk)\n            i += (chunk_size - overlap)\n        return [c.strip() for c in chunks if c.strip()]\n\n    class SimpleVectorDB:\n        def __init__(self, texts, embedder_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n            self.model = SentenceTransformer(embedder_name)\n            self.texts = texts\n            emb = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True, normalize_embeddings=True)\n            self.index = faiss.IndexFlatIP(emb.shape[1])\n            self.index.add(emb.astype(np.float32))\n\n        def similarity_search(self, query, k=2):\n            q = self.model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(np.float32)\n            D, I = self.index.search(q, k)\n            class Doc:  # بسيط\n                def __init__(self, page_content): self.page_content = page_content\n            return [Doc(self.texts[i]) for i in I[0] if i >= 0]\n\n    print(\"Building VectorDB from:\", PDF_PATH)\n    pdf_text = load_pdf_text(PDF_PATH)\n    chunks = chunk_text(pdf_text)\n    vectordb = SimpleVectorDB(chunks)\n    print(\"VectorDB ready. Chunks:\", len(chunks))\nelse:\n    print(\"Using existing vectordb.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:47:25.947717Z","iopub.execute_input":"2025-09-28T19:47:25.948309Z","iopub.status.idle":"2025-09-28T19:47:31.667578Z","shell.execute_reply.started":"2025-09-28T19:47:25.948281Z","shell.execute_reply":"2025-09-28T19:47:31.666929Z"}},"outputs":[{"name":"stdout","text":"Building VectorDB from: /kaggle/input/egiptura-database/Egiptura Database.pdf\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b40c111ee7784951acde4a596405e66b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"946565714df3457e92fcb0e695f73f0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e24924e26e4419081df8997ab705a56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de1c90457200478d8a3455c23b00048c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a273f0659bc04b67b8b223d0f4307334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b41d0aa28d034bb598d5487d8c57d011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0835d27ea834cecace2040dd493d586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460db7b3ee674765b99f74ab7c2866a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c60f5ad7aed0460b98c95b514a56b77f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"488a09ede55f41c7bb0fc6735d932622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1836451101b54ec49737c9e49d8c85aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428535a4030e4b368bd8965d2e00309d"}},"metadata":{}},{"name":"stdout","text":"VectorDB ready. Chunks: 137\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===== Build / Load PDF index (FAISS + E5 multilingual) =====\n!pip -q install langchain-community langchain-text-splitters faiss-cpu pypdf sentence-transformers\n\nimport os, glob, torch, re\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# --- Embeddings: E5 (متعدد اللغات) مع التطبيع + الـprefixات المناسبة\nclass E5Embeddings(HuggingFaceEmbeddings):\n    def embed_documents(self, texts):\n        return super().embed_documents([f\"passage: {t}\" for t in texts])\n    def embed_query(self, text):\n        return super().embed_query(f\"query: {text}\")\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nEMB_MODEL = \"intfloat/multilingual-e5-base\"  # جيّد للعربي/الإسباني/الإنجليزي\nemb = E5Embeddings(\n    model_name=EMB_MODEL,\n    model_kwargs={\"device\": DEVICE},\n    encode_kwargs={\"normalize_embeddings\": True},\n)\n\nINDEX_DIR = \"egiptura_index\"\n\ndef build_pdf_index(pdf_paths, persist_dir=INDEX_DIR, rebuild=False):\n    # حمّل الصفحات مع metadata (المصدر + رقم الصفحة)\n    docs = []\n    for p in pdf_paths:\n        try:\n            loader = PyPDFLoader(p)\n            pages  = loader.load()\n            for i, d in enumerate(pages, start=1):\n                d.metadata = d.metadata or {}\n                d.metadata.update({\"source\": os.path.basename(p), \"page\": i})\n            docs.extend(pages)\n        except Exception as e:\n            print(f\"[!] تخطي {p}: {e}\")\n\n    if not docs:\n        raise RuntimeError(\"لا يوجد مستندات PDF محمّلة. تأكد من المسارات.\")\n\n    # تقسيم ذكي\n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=800, chunk_overlap=150,\n        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n    )\n    chunks = splitter.split_documents(docs)\n    print(f\"[i] Chunks: {len(chunks)}\")\n\n    # بناء فهرس FAISS\n    vectordb = FAISS.from_documents(chunks, emb)\n    if persist_dir:\n        os.makedirs(persist_dir, exist_ok=True)\n        vectordb.save_local(persist_dir)\n        print(f\"[✓] Saved index -> {persist_dir}\")\n    return vectordb\n\ndef load_or_build_index(pdf_glob_pattern=\"*.pdf\", persist_dir=INDEX_DIR):\n    # لو فيه index محفوظ: حمّله، وإلا ابنِ جديد\n    if os.path.isdir(persist_dir) and os.path.exists(os.path.join(persist_dir, \"index.faiss\")):\n        print(f\"[i] Loading index from {persist_dir}\")\n        return FAISS.load_local(persist_dir, emb, allow_dangerous_deserialization=True)\n    pdfs = sorted(glob.glob(pdf_glob_pattern))\n    if not pdfs:\n        raise RuntimeError(\"لم أجد PDF. عدّل الـglob مثلاً: 'data/**/*.pdf'\")\n    print(f\"[i] Building index from {len(pdfs)} PDFs\")\n    return build_pdf_index(pdfs, persist_dir=persist_dir)\n\n# شغّل واحدة من الاتنين (حسب مكان ملفاتك):\n# vectordb = load_or_build_index(\"/kaggle/input/egiptura-database/**/*.pdf\")  # مثال على كاجل\nvectordb = load_or_build_index(\"**/*.pdf\")  # عدّل الباترن لمسار ملفاتك\n\n# --- (اختياري قوي) Reranker متعدد اللغات لتحسين النتائج\ntry:\n    from sentence_transformers import CrossEncoder\n    RERANKER = CrossEncoder(\"BAAI/bge-reranker-v2-m3\", device=DEVICE)  # يدعم AR/ES/EN\n    print(\"[✓] Reranker ready (BAAI/bge-reranker-v2-m3).\")\nexcept Exception as e:\n    RERANKER = None\n    print(f\"[i] Reranker disabled: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T20:45:23.048427Z","iopub.execute_input":"2025-09-28T20:45:23.049278Z","iopub.status.idle":"2025-09-28T20:45:29.570552Z","shell.execute_reply.started":"2025-09-28T20:45:23.049224Z","shell.execute_reply":"2025-09-28T20:45:29.569329Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_140/2131999347.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# شغّل واحدة من الاتنين (حسب مكان ملفاتك):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# vectordb = load_or_build_index(\"/kaggle/input/egiptura-database/**/*.pdf\")  # مثال على كاجل\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mvectordb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_or_build_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**/*.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# عدّل الباترن لمسار ملفاتك\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# --- (اختياري قوي) Reranker متعدد اللغات لتحسين النتائج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_140/2131999347.py\u001b[0m in \u001b[0;36mload_or_build_index\u001b[0;34m(pdf_glob_pattern, persist_dir)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mpdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_glob_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"لم أجد PDF. عدّل الـglob مثلاً: 'data/**/*.pdf'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[i] Building index from {len(pdfs)} PDFs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_pdf_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: لم أجد PDF. عدّل الـglob مثلاً: 'data/**/*.pdf'"],"ename":"RuntimeError","evalue":"لم أجد PDF. عدّل الـglob مثلاً: 'data/**/*.pdf'","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"# ===== Egiptura: رد سريع + لغة واحدة + سؤال متابعة واحد فقط (مع تنظيف وتصحيح) =====\nimport re, torch\n\n# إعدادات عامة\n_MAX_CTX   = 600\n_MAX_NEW   = 160\n_NO_REPEAT = 6\n_REP_PEN   = 1.2\n\n# كواشف/أنماط\n_AR  = re.compile(r\"[\\u0600-\\u06FF]\")\n_LAT = re.compile(r\"[A-Za-zÁÉÍÓÚÜÑáéíóúüñ]\")\n\n# رموز وأسطر خاصة يجب تنظيفها\n_SPECIAL         = re.compile(r\"(?:<\\|[^>|]+?\\|>)|(?:</?s>)|(?:<<SYS>>|<</SYS>>)|(?:\\[\\s*/?\\s*INST\\s*\\])|(?:<!\\[CDATA\\[|\\]\\]>)|(?:<\\/?\\w+\\s*>)\", re.IGNORECASE)\n_PREFIX_LINE     = re.compile(r'(?im)^\\s*(?:A|Ans|Resp|Rpta|Respuesta|Answer|الإجابة)\\s*:?\\s*')\n_PREFIX_INLINE   = re.compile(r'(?i)\\b(?:respuesta|answer|الإجابة)\\s*:?\\s*')\n_DISCLAIMER      = re.compile(r'^\\s*(?:nota|note|ملاحظة|تنبيه)\\s*[:\\-–]', re.IGNORECASE)\n_EMPTY_LIST_LINE = re.compile(r'^\\s*(?:[-–—•\\u2022]|\\(?\\d{1,3}\\)?[.)]?)\\s*$')\n_DECOR_LINE      = re.compile(r'^[\\.\\-=_~•·\\u2022\\s]{4,}$')\n_EMOJI_RE        = re.compile(r\"[\\U0001F300-\\U0001F6FF\\U0001F900-\\U0001FAFF\\U0001F1E6-\\U0001F1FF\\u2600-\\u26FF\\u2700-\\u27BF]\")\n\n# بقايا توكنات/رموز غريبة\n_JUNK_TOK_RE     = re.compile(r\"(?:</?s>|<s>|</s>|<<SYS>>|<</SYS>>|\\[/?INST\\])\", re.I)\n_JUNK_SYMBOLS_RE = re.compile(r\"[<>\\[\\]\\|/\\\\]{1,}\")\n_TAGGY_RE        = re.compile(r\"</?[A-Za-z][^>]{0,20}>\")\n\n# كشف الأسعار ومنعها\n_PRICE = re.compile(\n    r\"(?:\\$\\s?\\d+(?:[,\\.\\s]\\d+)*)|\"\n    r\"(?:\\d+\\s?(?:USD|EUR|EGP|AED|SAR))|\"\n    r\"(?:(?:USD|EUR|EGP|AED|SAR)\\s?\\d+(?:[,\\.\\s]\\d+)*)|\"\n    r\"(?:\\d+\\s?(?:دولار|يورو|جنيه|ريال|درهم))|\"\n    r\"(?:precio|coste|costo|price)\\s*(?:aprox\\.?|estimado)?\\s*:?[\\s~]*\\d+\",\n    re.IGNORECASE\n)\n\n# أسئلة/لغة\n_QLINE_RE = re.compile(r\"\\s*(?:[¿].*|\\S.*[?؟])\\s*$\")\n_AR_CH    = r\"[\\u0600-\\u06FF]\"\n_LAT_CH   = r\"[A-Za-zÁÉÍÓÚÜÑáéíóúüñ]\"\n\n# ===================== Helpers =====================\n\ndef _detect_lang(q: str) -> str:\n    s = q.strip().lower()\n    if _AR.search(s): \n        return \"ar\"\n    if re.search(r\"[áéíóúüñ¿¡]\", s) or any(w in s for w in (\n        \"hola\",\"buenas\",\"gracias\",\"quiero\",\"viaje\",\"programa\",\"itinerario\",\n        \"semana\",\"egipto\",\"viajar\",\"turismo\",\"precio\",\"coste\",\"costo\",\n        \"cuanto\",\"cuánto\"\n    )):\n        return \"es\"\n    return \"en\"\n\ndef _wants_price(q: str) -> bool:\n    s = q.lower()\n    return any(k in s for k in [\"price\",\"cost\",\"budget\",\"how much\",\"cuanto\",\"cuánto\",\"precio\",\"coste\",\"costo\",\"tarifa\",\"سعر\",\"التكلفة\",\"تكلفة\",\"ميزانية\"])\n\ndef _is_factoid(q: str) -> bool:\n    ql = q.strip().lower()\n    words = len(ql.split())\n    return words <= 12 and bool(re.search(r\"\\b(quien|quién|que|qué|cuando|cuándo|donde|dónde|who|what|when|where|من|ما|متى|أين)\\b\", ql))\n\ndef _trim_tokens(text: str, max_tokens: int) -> str:\n    global tok, tokenizer\n    tok = tok if 'tok' in globals() else tokenizer\n    ids = tok.encode(text, add_special_tokens=False)\n    return text if len(ids) <= max_tokens else tok.decode(ids[:max_tokens], skip_special_tokens=True)\n\ndef _strip_decor(text: str) -> str:\n    out = []\n    for ln in text.splitlines():\n        if _DECOR_LINE.match(ln.strip()):\n            continue\n        ln = re.sub(r'([.\\-=_~•·\\u2022])\\1{2,}', r'\\1\\1', ln)\n        out.append(ln)\n    return \"\\n\".join(out).strip()\n\ndef _strip_emojis(text: str) -> str:\n    return _EMOJI_RE.sub(\"\", text)\n\ndef _strip_token_garbage(t: str) -> str:\n    t = _JUNK_TOK_RE.sub(\"\", t)\n    t = _TAGGY_RE.sub(\"\", t)\n    t = _JUNK_SYMBOLS_RE.sub(\" \", t)\n    t = re.sub(r\"\\s{2,}\", \" \", t)\n    return t.strip()\n\ndef _clean(text: str) -> str:\n    text = _SPECIAL.sub(\"\", text)\n    text = _PREFIX_LINE.sub(\"\", text)\n    text = _PREFIX_INLINE.sub(\"\", text)\n    text = re.sub(r\"[ \\t]+\", \" \", text)\n    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n    text = \"\\n\".join([ln for ln in text.splitlines() if not _DISCLAIMER.match(ln.strip())])\n    text = \"\\n\".join([ln for ln in text.splitlines() if not _EMPTY_LIST_LINE.match(ln)])\n    # إزالة تكرارات\n    lines, seen = [], set()\n    for ln in text.splitlines():\n        k = ln.strip()\n        if not k:\n            lines.append(\"\")\n            continue\n        if k not in seen:\n            seen.add(k); lines.append(ln)\n    text = \"\\n\".join(lines).strip()\n    text = _strip_decor(text)\n    return text\n\n# فلترة لغة واحدة (أخفّ علشان الأرقام/الوحدات ما تتشالش)\ndef _enforce_lang(text: str, lang: str) -> str:\n    def keep_line(line: str) -> bool:\n        ar  = sum(1 for ch in line if _AR.match(ch))\n        lat = sum(1 for ch in line if re.match(r\"[A-Za-zÁÉÍÓÚÜÑáéíóúüñ]\", ch))\n        if ar == 0 and lat == 0:\n            return True\n        if lang == \"ar\": return ar  >= max(2, int(1.2 * lat))\n        if lang == \"es\": return lat >= max(2, int(1.0 * ar))\n        return lat >= max(2, int(1.0 * ar))\n    return \"\\n\".join([ln for ln in text.splitlines() if keep_line(ln)])\n\n# إزالة ترجمات داخل أقواس بلغة مختلفة\n_PARENS_RE = re.compile(r\"\\(([^)]{1,160})\\)\")\n_BRACK_RE  = re.compile(r\"\\[([^\\]]{1,160})\\]\")\ndef _strip_cross_parentheticals(text: str, lang: str) -> str:\n    def bad_chunk(chunk: str) -> bool:\n        has_ar  = bool(_AR.search(chunk))\n        has_lat = bool(re.search(r\"[A-Za-zÁÉÍÓÚÜÑáéíóúüñ]\", chunk))\n        if lang == \"ar\":  return has_lat and not has_ar\n        if lang == \"es\":  return has_ar and not has_lat\n        return has_ar\n    def repl_parens(m): return \"\" if bad_chunk(m.group(1)) else m.group(0)\n    def repl_brack(m):  return \"\" if bad_chunk(m.group(1)) else m.group(0)\n    text = _PARENS_RE.sub(repl_parens, text)\n    text = _BRACK_RE.sub(repl_brack, text)\n    return text\n\ndef _strip_prices_if_needed(text: str, allow: bool) -> str:\n    return text if allow else _PRICE.sub(\"▢\", text).strip()\n\ndef _is_greeting(q: str) -> bool:\n    return bool(re.search(r\"\\b(hola|buenas|hi|hello|hey|salut|مرحبا|اهلا|أهلاً|السلام عليكم)\\b\", q.strip().lower()))\n\ndef _normalize_question(q: str, lang: str) -> str:\n    q = _strip_emojis(q)\n    q = re.sub(r\"[?؟]{2,}\", \"?\", q)\n    q = re.sub(r\"[!¡]{2,}\", \"!\", q)\n    q = re.sub(r\"[.\\u2026]{3,}\", \"…\", q)\n    q = re.sub(r\"\\s{2,}\", \" \", q).strip()\n    if lang == \"ar\":\n        q = q.replace(\"¿\", \"\").replace(\"?\", \"؟\")\n        if not q.endswith(\"؟\"): q = q.rstrip(\"؟\") + \"؟\"\n    elif lang == \"es\":\n        q = q.rstrip(\"?\") + \"?\"\n        if not q.startswith(\"¿\"): q = \"¿\" + q\n    else:\n        q = q.replace(\"¿\", \"\")\n        q = q.rstrip(\"?\") + \"?\"\n    return q.strip()\n\ndef _line_matches_lang(line: str, lang: str) -> bool:\n    has_ar  = bool(re.search(_AR_CH, line))\n    has_lat = bool(re.search(_LAT_CH, line))\n    if lang == \"ar\": return has_ar and not (has_lat and not has_ar)\n    if lang == \"es\": return has_lat and not has_ar\n    return has_lat and not has_ar\n\ndef _enforce_one_followup(text: str, lang: str) -> str:\n    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n    keep_idx = None\n    for i in range(len(lines) - 1, -1, -1):\n        ln = lines[i]\n        if _QLINE_RE.match(ln) and _line_matches_lang(ln, lang):\n            keep_idx = i\n            break\n    cleaned = []\n    for i, ln in enumerate(lines):\n        if _QLINE_RE.match(ln):\n            if i == keep_idx:\n                cleaned.append(ln)\n        else:\n            cleaned.append(ln)\n    if keep_idx is None:\n        fallback = {\n            \"ar\": \"هل تود أن أضيف تفاصيل محددة؟\",\n            \"es\": \"¿Quieres que añada algún detalle en concreto?\",\n            \"en\": \"Would you like me to add any specific details?\",\n        }.get(lang, \"Would you like me to add any specific details?\")\n        cleaned.append(fallback)\n    else:\n        if cleaned and _QLINE_RE.match(cleaned[-1]):\n            cleaned[-1] = _normalize_question(cleaned[-1], lang)\n    cleaned = [_strip_emojis(ln) for ln in cleaned]\n    return \"\\n\".join([ln for ln in cleaned if ln.strip()]).strip()\n\ndef _tone_open(text: str, lang: str, factoid: bool) -> str:\n    t = text.strip()\n    if not t:\n        return {\n            \"ar\": \"مرحبًا! كيف أقدر أساعدك في رحلتك إلى مصر؟\",\n            \"es\": \"¡Hola! ¿En qué puedo ayudarte con tu viaje a Egipto?\",\n            \"en\": \"Hi! How can I help with your Egypt trip?\",\n        }.get(lang, \"Hi! How can I help?\")\n    if factoid:\n        return t\n    openings = {\"ar\": \"بكل سرور — \", \"es\": \"¡Claro! \", \"en\": \"Sure — \"}\n    if not t.lower().startswith(tuple(s.lower() for s in openings.values())):\n        t = openings.get(lang, \"Sure — \") + t\n    return re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n\n# تصحيح حقائق شائعة\ndef _post_fix_facts(text: str, lang: str) -> str:\n    if lang == \"ar\":\n        text = re.sub(r\"\\bالمملكة\\s+المصرية\\b\", \"جمهورية مصر العربية\", text)\n    elif lang == \"es\":\n        text = re.sub(r\"\\bReino\\s+de\\s+Egipto\\b\", \"República Árabe de Egipto\", text, flags=re.I)\n    else:\n        text = re.sub(r\"\\bKingdom of Egypt\\b\", \"Arab Republic of Egypt\", text, flags=re.I)\n    return text\n\n# إجابة جاهزة لبعض الأسئلة لتقليل الهلوسة (مثال: مساحة مصر)\ndef _fact_override(question: str, lang: str):\n    q = question.strip().lower()\n    if (lang == \"ar\" and (\"كم مساحة مصر\" in q or \"مساحة مصر\" in q)) \\\n       or (lang == \"es\" and re.search(r\"(superficie|área).*(egipto)\", q)) \\\n       or (lang == \"en\" and re.search(r\"(area|size).*(egypt)\", q)):\n        if lang == \"ar\":\n            return \"بكل سرور — مساحة **جمهورية مصر العربية** حوالي **1,001,450 كم²** (≈ **1.0 مليون كم²**). هل تود أن أضيف تفاصيل محددة؟\"\n        elif lang == \"es\":\n            return \"¡Claro! La superficie de la **República Árabe de Egipto** es de **~1.001.450 km²** (≈ **1,0 millón km²**). ¿Quieres algún detalle más?\"\n        else:\n            return \"Sure — The area of the **Arab Republic of Egypt** is **about 1,001,450 km²** (≈ **1.0 million km²**). Would you like any specific details?\"\n    return None\n\n# بناء البرومبت\ndef _build_prompts(lang: str, context: str, question: str):\n    if lang == \"ar\":\n        system = (\n            \"أنت مساعد Egiptura الودود والمحترف. أجب بالعربية الفصحى فقط وبلا أي مزج لغات أو ترجمات. \"\n            \"أنت متخصص في السياحة داخل مصر وتاريخها والرحلات إلى مصر؛ لا تتحدث عن مواضيع لا صلة لها بمصر. \"\n            \"نظّم الإجابة بنقاط/أيام عند الحاجة وتجنّب تكرار السؤال. \"\n            \"إن لم تكن متأكدًا لا تُخمّن؛ اطلب أهم تفصيلة في جملة واحدة. \"\n            \"لا تذكر الأسعار إلا إذا سُئلت صراحة. \"\n            \"اكتفِ في النهاية بسؤال متابعة واحد قصير وبالعربية فقط عند الحاجة.\"\n        )\n        user = (f\"السياق (اختياري):\\n{context}\\n\\nسؤال:\\n{question}\\n\\n\"\n                \"أعطني الإجابة مباشرة بدون إعادة صياغة السؤال.\")\n    elif lang == \"es\":\n        system = (\n            \"Eres el asistente de Egiptura. Responde SOLO en español, sin mezclar idiomas ni hacer traducciones. \"\n            \"Te especializas en turismo, historia egipcia y viajes a Egipto. No hables de otros temas. \"\n            \"Sé claro y conciso; usa viñetas/días cuando ayude. \"\n            \"Si no estás seguro, no inventes: pide el dato clave en una sola frase. \"\n            \"No menciones precios salvo que el usuario lo pida. \"\n            \"Termina, si hace falta, con UNA sola pregunta breve en español.\"\n        )\n        user = (f\"Contexto (opcional):\\n{context}\\n\\nPregunta:\\n{question}\\n\\n\"\n                \"Dame la respuesta directa sin repetir el enunciado.\")\n    else:\n        system = (\n            \"You are Egiptura’s assistant. Reply ONLY in English—no code-switching or translations. \"\n            \"You specialize in tourism, Egyptian history, and trips to Egypt; don't discuss unrelated topics. \"\n            \"Be concise; use bullets/day-by-day when helpful. \"\n            \"If unsure, don’t fabricate; ask for the key detail in one short sentence. \"\n            \"Do not mention pricing unless asked. \"\n            \"If needed, end with ONE short follow-up question in English.\"\n        )\n        user = (f\"Context (optional):\\n{context}\\n\\nQuestion:\\n{question}\\n\\n\"\n                \"Return the direct answer without repeating the prompt.\")\n    return system, user\n\n# ===================== الدالة الرئيسية =====================\n\ndef answer(question: str) -> str:\n    \"\"\"\n    يُعيد ردًا سريعًا بلغة واحدة، نظيفًا، بدون أسعار (إلا لو سُئلت)،\n    وينتهي بسؤال متابعة واحد فقط بنفس اللغة.\n    \"\"\"\n    global tok, tokenizer, model, vectordb\n    tok = tok if 'tok' in globals() else tokenizer\n\n    user_q = question.strip()\n    lang   = _detect_lang(user_q)\n\n    # تحيات: رد فوري\n    if _is_greeting(user_q):\n        return {\n            \"ar\": \"مرحبًا! كيف أقدر أساعدك في رحلتك إلى مصر؟\",\n            \"es\": \"¡Hola! ¿En qué puedo ayudarte con tu viaje a Egipto?\",\n            \"en\": \"Hi! How can I help with your Egypt trip?\",\n        }.get(lang, \"Hi! How can I help?\")\n\n    # إجابة جاهزة لبعض الحقائق (تقليل الهلوسة)\n    ov = _fact_override(user_q, lang)\n    if ov:\n        return ov\n\n    fact  = _is_factoid(user_q)\n    wants = _wants_price(user_q)\n\n    # RAG خفيف (اختياري)\n    context = \"\"\n    if 'vectordb' in globals() and vectordb:\n        try:\n            docs = vectordb.similarity_search(user_q, k=1) or []\n            if docs:\n                context = _trim_tokens(\"\\n\\n\".join(d.page_content for d in docs), _MAX_CTX)\n        except Exception:\n            context = \"\"\n\n    system, user = _build_prompts(lang, context, user_q)\n\n    # ترميز\n    use_template = hasattr(tok, \"apply_chat_template\") and getattr(tok, \"chat_template\", None)\n    if use_template:\n        messages = [{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}]\n        enc = tok.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(model.device)\n        if isinstance(enc, torch.Tensor):\n            ins = {\"input_ids\": enc, \"attention_mask\": torch.ones_like(enc)}\n        elif isinstance(enc, dict):\n            ids = enc[\"input_ids\"]; attn = enc.get(\"attention_mask\", torch.ones_like(ids))\n            ins = {\"input_ids\": ids, \"attention_mask\": attn}\n        else:\n            ids = enc.input_ids; attn = getattr(enc, \"attention_mask\", None) or torch.ones_like(ids)\n            ins = {\"input_ids\": ids, \"attention_mask\": attn}\n    else:\n        prompt = f\"{system}\\n\\nUSER:\\n{user}\\n\\nASSISTANT:\\n\"\n        enc = tok(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n        ins = {\"input_ids\": enc[\"input_ids\"],\n               \"attention_mask\": enc.get(\"attention_mask\", torch.ones_like(enc[\"input_ids\"]))}\n\n    # IDs وممنوعات\n    def _tid(s):\n        try:\n            t = tok.convert_tokens_to_ids(s)\n            return t if isinstance(t, int) and t >= 0 else None\n        except Exception:\n            return None\n    eos = tok.eos_token_id or _tid(\"</s>\") or _tid(\"<|eot_id|>\") or _tid(\"<|end_of_text|>\")\n    pad = tok.pad_token_id if tok.pad_token_id is not None else eos\n    bad = [t for t in [_tid(\"</s>\"), _tid(\"<s>\"), _tid(\"[INST]\"), _tid(\"[/INST]\"),\n                       _tid(\"<<SYS>>\"), _tid(\"<</SYS>>\"),\n                       _tid(\"<|user|>\"), _tid(\"<|assistant|>\"), _tid(\"<|system|>\")] if isinstance(t, int)]\n\n    gen_kwargs = dict(\n        max_new_tokens=min(_MAX_NEW, 96 if fact else _MAX_NEW),\n        use_cache=True,\n        eos_token_id=eos,\n        pad_token_id=pad,\n        no_repeat_ngram_size=_NO_REPEAT,\n        repetition_penalty=_REP_PEN,\n        num_beams=1,\n        do_sample=False,  # سريع وثابت\n    )\n    if bad: gen_kwargs[\"bad_words_ids\"] = [[i] for i in bad]\n\n    with torch.inference_mode():\n        out = model.generate(**ins, **gen_kwargs)\n\n    gen_only = out[0, ins[\"input_ids\"].shape[-1]:]\n    text = tok.decode(gen_only, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n\n    # Post: نظافة كاملة + إزالة رموز + لغة واحدة + تصحيح حقائق + سؤال واحد + منع أسعار + نبرة لطيفة\n    text = _clean(text)\n    text = _strip_token_garbage(text)\n    text = _strip_cross_parentheticals(text, lang)\n    text = _enforce_lang(text, lang)\n    text = _post_fix_facts(text, lang)\n    text = _enforce_one_followup(text, lang)\n    text = _strip_prices_if_needed(text, allow=wants)\n    text = _tone_open(text, lang, factoid=fact)\n    return text.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T20:32:06.171032Z","iopub.execute_input":"2025-09-28T20:32:06.171385Z","iopub.status.idle":"2025-09-28T20:32:06.211707Z","shell.execute_reply.started":"2025-09-28T20:32:06.171359Z","shell.execute_reply":"2025-09-28T20:32:06.210892Z"}},"outputs":[{"name":"stdout","text":"INFO:     154.182.78.241:0 - \"OPTIONS /generate HTTP/1.1\" 200 OK\nINFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d445a7ddd648c8bb494ef77ff304d8"}},"metadata":{}},{"name":"stdout","text":"INFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\nINFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4e48a32fa0947688ac197fce4d4ae86"}},"metadata":{}},{"name":"stdout","text":"INFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb7a7206bdc439dbbac3cf23f878c38"}},"metadata":{}},{"name":"stdout","text":"INFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(answer(\"¿Quién es el rey Ahmose?\"))          # رد معرفي سريع، بدون قوائم فاضية ولا ملاحظات\nprint(answer(\"عايز برنامج 7 أيام في مصر\"))          # نقاط مختصرة وبأسلوب لطيف\nprint(answer(\"How much for 1-week Egypt for 4?\"))  # يسمح بالأسعار لأن السؤال طلبها صراحة\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:47:46.178503Z","iopub.execute_input":"2025-09-28T19:47:46.178809Z","iopub.status.idle":"2025-09-28T19:48:39.793056Z","shell.execute_reply.started":"2025-09-28T19:47:46.178784Z","shell.execute_reply":"2025-09-28T19:48:39.792368Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7b82691118b42babcca8cf032b43492"}},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"El faraón egipcio que lideró la batalla contra los hititas para liberar Egipto. ¿Cómo ha influido esta victoria en la historia? . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n¿Quieres que añada algún detalle en concreto?\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f3b0a60ccf45c881a0d18ffc7420cb"}},"metadata":{}},{"name":"stdout","text":"بكل سرور — برنامج 7 أيام: ديا على الأهرامات، يومين للبحث عن التماثيل، يومين للزيارة إلى أبو سمبل، يومين للرحلة البحرية من أسوان إلى القاهرة. انتهاءً بزيارة إلى مسجد سيدي محمد البارقي. يبدأ البرنامج من القاهرة ويستمر حتى القاهرة. يتم تقاسم الطعام مع العائلة المحلية. يمكنك اختيار بين أنواع الغرف المتوفرة. جميع الخدمات تشمل غرفة نوم مريحة ومطبخ محلي. تمتلك المدينة قصرا كبيرا يضم العديد من المساحات المفتوحة والغابات الطبيعية. يتم تنظيم\nهل تود أن أضيف تفاصيل محددة؟\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ce7e4dce2841f3870682fdf828c651"}},"metadata":{}},{"name":"stdout","text":"Sure — For a single room at Categoría Gold during low season: $3,440. For a double room at Categoría Diamond during high season: $12,255. Next?\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===== FastAPI + ngrok server for Egiptura =====\nimport os, re, time, socket, threading\nimport requests, nest_asyncio, uvicorn\nfrom fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pyngrok import ngrok, conf\n\n# --- Config ---\nAPI_KEY           = os.getenv(\"API_KEY\", \"secret123\")\nPREFERRED_PORT    = int(os.getenv(\"PORT\", \"8000\"))\nNGROK_AUTH_TOKEN  = (os.getenv(\"NGROK_AUTH_TOKEN\") or os.getenv(\"NGROK_TOKEN\") or \"32JYankevjVACV9Gy2F0KQ2YhJ8_6Fne9bccQciyPpEtcJAKR\").strip()\n\n# --- App ---\napp = FastAPI()\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],   # TODO: في الإنتاج حدِّد الدومينات المسموح بها\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n@app.get(\"/alive\")\nasync def alive():\n    return {\"ok\": True}\n\n@app.post(\"/generate\")\nasync def generate(req: Request):\n    # Auth\n    auth = req.headers.get(\"authorization\") or req.headers.get(\"Authorization\") or \"\"\n    if auth != f\"Bearer {API_KEY}\":\n        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n\n    # Read input\n    try:\n        data = await req.json()\n    except Exception:\n        raise HTTPException(status_code=400, detail=\"Invalid JSON body\")\n\n    q = (data.get(\"query\") or data.get(\"prompt\") or \"\").strip()\n    if not q:\n        raise HTTPException(status_code=400, detail=\"Missing 'query' (or 'prompt').\")\n\n    # Call model function (prefer 'answer', fallback to 'chat')\n    try:\n        if \"answer\" in globals():\n            text = answer(q)\n        elif \"chat\" in globals():\n            text = chat(q)\n        else:\n            raise RuntimeError(\"No model function found: define answer(question) or chat(user_msg).\")\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"{type(e).__name__}: {e}\")\n\n    text = (text or \"\").strip()\n    return {\"response\": text}\n\n# --- Uvicorn in background thread ---\nnest_asyncio.apply()\n_server = None\n\ndef _port_is_free(port: int) -> bool:\n    try:\n        import socket as _s\n        with _s.socket(_s.AF_INET, _s.SOCK_STREAM) as s:\n            s.bind((\"0.0.0.0\", port))\n            return True\n    except OSError:\n        return False\n\ndef pick_free_port(preferred: int = 8000) -> int:\n    if _port_is_free(preferred):\n        return preferred\n    s = socket.socket()\n    s.bind((\"\", 0))\n    port = s.getsockname()[1]\n    s.close()\n    return port\n\ndef start_uvicorn_in_thread(port: int):\n    global _server\n    config = uvicorn.Config(app, host=\"0.0.0.0\", port=port, log_level=\"info\")\n    _server = uvicorn.Server(config)\n    th = threading.Thread(target=_server.run, daemon=True)\n    th.start()\n    # wait until alive\n    for _ in range(60):\n        try:\n            r = requests.get(f\"http://127.0.0.1:{port}/alive\", timeout=0.5)\n            if r.ok:\n                break\n        except Exception:\n            pass\n        time.sleep(0.25)\n    return th\n\ndef stop_all_tunnels():\n    try:\n        for t in ngrok.get_tunnels():\n            ngrok.disconnect(t.public_url)\n    except Exception:\n        pass\n\ndef start_ngrok_for_port(port: int) -> str:\n    if not NGROK_AUTH_TOKEN:\n        raise RuntimeError(\"NGROK_AUTH_TOKEN is not set. Put it in env then rerun.\")\n    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n    stop_all_tunnels()\n    url = ngrok.connect(addr=f\"http://127.0.0.1:{port}\", proto=\"http\").public_url\n    print(f\"🌍 Public URL: {url}\")\n    print(f\"🔗 Swagger:   {url}/docs\")\n    return url\n\ndef run_server_with_ngrok(preferred_port: int = PREFERRED_PORT):\n    port = pick_free_port(preferred_port)\n    start_uvicorn_in_thread(port)\n    return start_ngrok_for_port(port)\n\npublic_url = run_server_with_ngrok(PREFERRED_PORT)\nprint(\"✅ Ready! Use POST /generate with {'query': '...'} and Authorization: Bearer API_KEY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:49:00.483790Z","iopub.execute_input":"2025-09-28T19:49:00.484420Z","iopub.status.idle":"2025-09-28T19:49:02.114087Z","shell.execute_reply.started":"2025-09-28T19:49:00.484396Z","shell.execute_reply":"2025-09-28T19:49:02.113455Z"}},"outputs":[{"name":"stderr","text":"INFO:     Started server process [140]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"INFO:     127.0.0.1:55012 - \"GET /alive HTTP/1.1\" 200 OK\n🌍 Public URL: https://cbfd92cc65a2.ngrok-free.app                                                  \n🔗 Swagger:   https://cbfd92cc65a2.ngrok-free.app/docs\n✅ Ready! Use POST /generate with {'query': '...'} and Authorization: Bearer API_KEY\nINFO:     154.182.78.241:0 - \"OPTIONS /generate HTTP/1.1\" 200 OK\nINFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b320e85225114897a3cd69ab6c3c3097"}},"metadata":{}},{"name":"stdout","text":"INFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed7d57575bb640dd8c82367e3cb61d86"}},"metadata":{}},{"name":"stdout","text":"INFO:     154.182.78.241:0 - \"POST /generate HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"q=\"how much the journey in egypt for week cost in octoper with gold category for 10 persons?\"\nx=ask_question(q)\nprint(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:45:41.477794Z","iopub.status.idle":"2025-09-28T19:45:41.478115Z","shell.execute_reply.started":"2025-09-28T19:45:41.477954Z","shell.execute_reply":"2025-09-28T19:45:41.477970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q=\"¿Quién es el rey Ahmos?\"\nx=ask_question(q)\nprint(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T19:45:41.479207Z","iopub.status.idle":"2025-09-28T19:45:41.479485Z","shell.execute_reply.started":"2025-09-28T19:45:41.479379Z","shell.execute_reply":"2025-09-28T19:45:41.479390Z"}},"outputs":[],"execution_count":null}]}